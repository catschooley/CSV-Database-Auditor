{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Toolbox(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the toolbox (the name of the toolbox is the name of the\n",
    "        .pyt file).\"\"\"\n",
    "        self.label = \"CSV Auditor Toolbox\"\n",
    "        self.alias = \"CSVAt\"\n",
    "\n",
    "        # List of tool classes associated with this toolbox\n",
    "        self.tools = [Duplicate]\n",
    "\n",
    "\n",
    "class Duplicate(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the tool (tool name is the name of the class).\"\"\"\n",
    "        self.label = \"Duplicate Removal\"\n",
    "        self.description = \"Creates two new csv files. One with only the duplicates from the input table and one with the duplicates removed.\"\n",
    "        self.canRunInBackground = False\n",
    "\n",
    "    def getParameterInfo(self):\n",
    "        \"\"\"Define parameter definitions\"\"\"\n",
    "        \n",
    "        #first paramater which is the table to be audited\n",
    "        param0= arcpy.Parameter(\n",
    "            displayName = 'Table to be audited',\n",
    "            name = 'input_file',\n",
    "            datatype = 'DEFile',\n",
    "            parameterType = 'Required',\n",
    "            direction = 'Input')\n",
    "        #create a filter to force the file to be a csv\n",
    "            param0.filter.list = ['csv']\n",
    "            \n",
    "        #second parameter where the duplicate file will be stored\n",
    "        param1= arcpy.Parameter(\n",
    "            displayName = 'Duplicate File',\n",
    "            name = 'duplicate_file',\n",
    "            datatype = 'DEFile',\n",
    "            parameterType = 'Required',\n",
    "            direction = 'Output')\n",
    "        #create a filter that the output file must also be a csv\n",
    "            param1.filter.list = ['csv']\n",
    "        \n",
    "        #third parameter where the file containing no duplicates will be stored\n",
    "        param2= arcpy.Parameter(\n",
    "            displayName = 'Output File',\n",
    "            name = 'output_file',\n",
    "            datatype = 'DEFile',\n",
    "            parameterType = 'Required',\n",
    "            direction = 'Output')\n",
    "        #create a filter that the output file must also be a csv\n",
    "            param1.filter.list = ['csv']\n",
    "            \n",
    "        #fourth parameter field name of interest\n",
    "        param3 = arcpy.Parameter(\n",
    "            displayName = 'Field to Find Duplicates',\n",
    "            name = 'field',\n",
    "            datatype = 'Field',\n",
    "            parameterType = 'Required',\n",
    "            direction = 'Input')\n",
    "        \n",
    "        params = [param0, param1, param2, param3, param4]        \n",
    "        return params\n",
    "\n",
    "    def isLicensed(self):\n",
    "        \"\"\"Set whether tool is licensed to execute.\"\"\"\n",
    "        return True\n",
    "\n",
    "    def updateParameters(self, parameters):\n",
    "        \"\"\"Modify the values and properties of parameters before internal\n",
    "        validation is performed.  This method is called whenever a parameter\n",
    "        has been changed.\"\"\"\n",
    "        return\n",
    "\n",
    "    def updateMessages(self, parameters):\n",
    "        \"\"\"Modify the messages created by internal validation for each tool\n",
    "        parameter.  This method is called after internal validation.\"\"\"\n",
    "        return\n",
    "\n",
    "    def execute(self, parameters, messages):\n",
    "        \"\"\"The source code of the tool.\"\"\"\n",
    "        \n",
    "        #get parameters\n",
    "        \n",
    "        input_file = parameters[0].valueAsText\n",
    "        duplicate_file = parameters[1].valueAsText\n",
    "        output_file = parameters[2].valueAsText\n",
    "        field = parameters[3].valueAsText\n",
    "        \n",
    "        \n",
    "        #this reads the csv as a dataframe\n",
    "        old_df = pd.read_csv(input_file)\n",
    "        \n",
    "        dup_idx = old_df.duplicated(field)\n",
    "        \n",
    "        dups = old_df[dup_idx]\n",
    "\n",
    "        #this writes those duplicates to a csv file determined above\n",
    "        dups.to_csv(duplicate_file)\n",
    "\n",
    "        #this creates the new file while dropping every duplicate except for the first time that\n",
    "        #the duplicate occurs\n",
    "        \n",
    "        newdf = old_df[~dup_idx]\n",
    "        \n",
    "        #this writes the new dif to a csv with no duplicates\n",
    "        no_dup = newdf.to_csv(output_file, index=False)Â \n",
    "        \n",
    "        messages.addMessage('Audit Complete')\n",
    "        \n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
